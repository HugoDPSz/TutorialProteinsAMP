# Protein Sequences Classification using AMP Dataset

Este projeto Ã© uma implementaÃ§Ã£o e adaptaÃ§Ã£o de um tutorial para classificaÃ§Ã£o de sequÃªncias de proteÃ­nas, com foco em peptÃ­deos antimicrobianos (AMPs). O objetivo Ã© treinar um modelo de aprendizado profundo capaz de distinguir entre sequÃªncias AMP e nÃ£o-AMP.

## ğŸ” VisÃ£o Geral

O notebook `tutorials_proteins_amp.ipynb` conduz as etapas de prÃ©-processamento de dados, construÃ§Ã£o do modelo, treinamento, avaliaÃ§Ã£o e visualizaÃ§Ã£o de resultados. Ele utiliza uma abordagem baseada em modelos de linguagem (transformers) para tarefas de classificaÃ§Ã£o binÃ¡ria em sequÃªncias proteicas.

## ğŸ§ª Tecnologias e Bibliotecas Utilizadas

- Python 3.11 (Colab)
- PyTorch
- HuggingFace Transformers
- Pandas, NumPy, Matplotlib
- scikit-learn
- tqdm

## ğŸ“ Estrutura do Projeto

- `tutorials_proteins_amp.ipynb`: notebook principal com toda a pipeline do projeto.
- Dataset de peptÃ­deos antimicrobianos (AMP) carregado via HuggingFace Datasets ou similar.

## ğŸš€ Etapas do Notebook

1. **ImportaÃ§Ã£o de bibliotecas**
2. **Carregamento e visualizaÃ§Ã£o dos dados**
3. **TokenizaÃ§Ã£o e preparaÃ§Ã£o das sequÃªncias proteicas**
4. **DivisÃ£o em treino, validaÃ§Ã£o e teste**
5. **CriaÃ§Ã£o do modelo com `AutoModelForSequenceClassification`**
6. **Treinamento com `Trainer`**
7. **AvaliaÃ§Ã£o usando mÃ©tricas como accuracy, precision, recall e F1**
8. **VisualizaÃ§Ãµes (ex: matriz de confusÃ£o)**

## âš™ï¸ Como Executar

1. Acesse o notebook no Google Colab.
2. Instale as dependÃªncias necessÃ¡rias com `pip install transformers datasets scikit-learn`.
3. Execute as cÃ©lulas sequencialmente.

> Obs.: O cÃ³digo foi adaptado para evitar warnings relacionados ao uso de mÃ©todos obsoletos, como `DataFrame.append()`.

## ğŸ“ CrÃ©ditos

Baseado em tutoriais da HuggingFace e materiais educacionais de bioinformÃ¡tica com aprendizado de mÃ¡quina. CustomizaÃ§Ãµes feitas por [Seu Nome Aqui].

## ğŸ“œ LicenÃ§a

Este projeto Ã© de uso educacional. Verifique a licenÃ§a do tutorial original, se aplicÃ¡vel.
